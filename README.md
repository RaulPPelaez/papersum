## Papersum
Summarize arxiv papers.
This tool will query arxiv for recent papers on a certain subject and will ask a large language model to summarize them.

You can use the OpenAI API for this (with any of its available models) or run any transformer from Huggingface locally on your machine (warning, this typically requires ~100GB of VRAM available)


### Installation

Run ```pip install -e .```

### Usage

Run ```papersum -h```

### Examples
Use the falcon pipeline for huggingface models (even non-falcon ones)
```bash
papersum --topic="neural network potentials" --max_papers=1 --pipeline=falcon --model="tiiuae/falcon-40b-instruct"
```
 
Use the openai pipeline for OpenAI models
```bash
papersum --topic="neural network potentials" --max_papers=1 --pipeline=openai --model="gpt-3.5-turbo-16k"
```

A summary is printed to screen and appended to a file called output.txt
## Typical output


```
$ papersum --topic="neural network potentials" --max_papers=1 --pipeline=openai --model="gpt-3.5-turbo-16k"
===========NEW ARTICLE==========
Exposing the Fake: Effective Diffusion-Generated Images Detection
------PROMPT------
Can you give me a very clear explanation of the core assertions, implications, and mechanics elucidated in this paper? Like you're talking to a CEO. So what? What's the bottom line here? Be as concise as posible, I must read it in under 30 seconds. Start your answer by stating the title of the paper. Below are the contents of the paper (note that the paper might be truncated):
------RESPONSE------
Title: Exposing the Fake: Effective Diffusion-Generated Images Detection

This paper addresses the need for detecting diffusion-generated images, which can pose security and privacy risks. The authors propose a novel detection method called SeDID,
 which leverages the unique properties of diffusion models, specifically the deterministic reverse and denoising errors. SeDID outperforms existing methods in detecting diff
usion-generated images, as demonstrated through extensive experiments on three datasets. This work makes a significant contribution to the field of artificial intelligence s
ecurity by effectively distinguishing between real and diffusion-generated images.
```

```
$ papersum --topic="neural network potentials" --max_papers=1 --pipeline=falcon --model="tiiuae/falcon-40b-instruct"
===========NEW ARTICLE==========
Exposing the Fake: Effective Diffusion-Generated Images Detection
------PROMPT------
Can you give me a very clear explanation of the core assertions, implications, and mechanics elucidated in this paper? Like you're talking to a CEO. So what? What's the bottom line here? Be as concise as posible, I must read it in under 30 seconds. Start your answer by stating the title of the paper. Below are the contents of the paper (note that the paper might be truncated):
------RESPONSE------
Can you provide a summary of the contents of the paper?
The paper proposes a novel detection method for identifying artificial images generated by diffusion models. The approach takes advantage of the unique properties of these models, such as their deterministic reverse and denoising computations, and incorporates insights from previous studies. The method employs different branches, including statistical analysis, error calculation, and neural network-based detection with ResNet-18, which processes images with predictability errors via backpropagation. The research results indicate that SeDID performs well compared to existing methods when applied to diffusion models, and it is a crucial step towards developing artificial intelligence security.
```
